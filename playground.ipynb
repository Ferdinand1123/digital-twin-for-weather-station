{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from utils.utils import pretty_lat, pretty_lon, ProgressStatus\n",
    "from tempfile import TemporaryDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from station.data_submission import DataSubmission\n",
    "from station.station import StationData\n",
    "\n",
    "from train_station_twin.training_executer import TrainingExecuter\n",
    "from infilling.evaluation_executer import EvaluatuionExecuter\n",
    "from infilling.infilling_writer import InfillingWriter\n",
    "\n",
    "from era5.era5_for_station import DownloadEra5ForStation, DownloadEra5ForStationGaps\n",
    "from era5.era5_download_hook import Era5DownloadHook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-03T12:40:34.826230Z",
     "start_time": "2024-04-03T12:40:34.429455Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_n_steps_of_area_from_nc_file(path, n=1, vars=\"tas\", title=\"\", vmin=None, vmax=None):\n",
    "\n",
    "    dataset = xr.open_dataset(path)\n",
    "\n",
    "    n = min(n, dataset.time.size)\n",
    "    time_index_list = np.random.choice(dataset.time.size, n, replace=False)\n",
    "\n",
    "    lat_slice = slice(None)\n",
    "    lon_slice = slice(None)\n",
    "    _lon = dataset.lon.values[lon_slice]\n",
    "    _lat = dataset.lat.values[lat_slice]\n",
    "\n",
    "    # if not list make it a list\n",
    "    if not isinstance(vars, list):\n",
    "        vars = [vars]\n",
    "\n",
    "    for time_index in time_index_list:\n",
    "        # set title\n",
    "        title += f\"\\n{dataset.time.values[time_index].astype('datetime64[s]').astype('O')}\"\n",
    "\n",
    "        # subtitle lat lon area\n",
    "        subtitle = f\"\\nLat: {pretty_lat(_lat[0])} to {pretty_lat(_lat[-1])}\" + \\\n",
    "            f\"\\nLon: {pretty_lon(_lon[0])} to {pretty_lon(_lon[-1])}\"\n",
    "\n",
    "        for var in vars:\n",
    "\n",
    "            # plot\n",
    "            fig, ax = plt.subplots(\n",
    "                subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "            # Plot the temperature data with a quadratic colormap\n",
    "            _data = dataset.variables[var].values[time_index, lat_slice, lon_slice]\n",
    "            pcm = ax.pcolormesh(_lon, _lat, _data, cmap='viridis',\n",
    "                                shading='auto', vmin=vmin, vmax=vmax)\n",
    "\n",
    "            # Add coastlines\n",
    "            ax.coastlines()\n",
    "\n",
    "            # Add colorbar\n",
    "            cbar = plt.colorbar(pcm, ax=ax, label='Temperature')\n",
    "\n",
    "            # Set labels and title\n",
    "            ax.set_xlabel('Longitude')\n",
    "            ax.set_ylabel('Latitude')\n",
    "            plt.title(title + (f\"\\n[{var}]\" if len(vars) > 1 else \"\"))\n",
    "\n",
    "            # position title a higher\n",
    "            plt.subplots_adjust(top=1)\n",
    "            \n",
    "            # Add subtitle\n",
    "            plt.figtext(0.125, 0.05, subtitle, wrap=True, horizontalalignment='left', fontsize=12)\n",
    "\n",
    "            # Show the plot\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Marshall_2017-2023...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 306/306 [00:19<00:00, 16.01it/s]\n"
     ]
    }
   ],
   "source": [
    "marshall_data = DataSubmission(\"Marshall_2017-2023\")\n",
    "marshall_data.measurement_dir_path = \"./measurements/Marshall/\"\n",
    "\n",
    "marshall_station = StationData(\n",
    "    name=marshall_data.name,\n",
    "    folder_path=marshall_data.measurement_dir_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7177,)\n",
      "Saving to /var/folders/yj/k7pg73d56rl366r8bvlbncgm0000gn/T/tmpxrz6o9jp/train/marshall_2017-2023.nc\n",
      "Downloading 2017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-15 23:41:25,084 INFO Welcome to the CDS\n",
      "2024-04-15 23:41:25,085 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/reanalysis-era5-single-levels\n",
      "2024-04-15 23:41:25,196 INFO Request is completed\n",
      "2024-04-15 23:41:25,197 INFO Downloading https://download-0017.copernicus-climate.eu/cache-compute-0017/cache/data2/adaptor.mars.internal-1713205445.4090545-24831-2-52ca6b2c-1219-4190-b653-f4db21242676.grib to /var/folders/yj/k7pg73d56rl366r8bvlbncgm0000gn/T/tmpr9nyfy9_/2017.grib (3M)\n",
      "2024-04-15 23:41:25,873 INFO Download rate 4.5M/s   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2017.grib\n",
      "Renamed variable var167 to tas in /var/folders/yj/k7pg73d56rl366r8bvlbncgm0000gn/T/tmpf0irwh95/2017.nc\n",
      "Found 2017.nc\n",
      "Merged era5 file saved into /var/folders/yj/k7pg73d56rl366r8bvlbncgm0000gn/T/tmpm7d1y6d5/era5_merged.nc\n",
      "Lat:  39.9496\n",
      "Lon:  254.804\n",
      "nearest_lat_idx: 4 [40.95     40.699875 40.44975  40.199625 39.9495   39.699375 39.44925\n",
      " 39.199125 38.949   ]\n",
      "nearest_lon_idx: 4 [253.804 254.054 254.304 254.554 254.804 255.054 255.304 255.554 255.804]\n",
      "nearest_lat: 39.9495\n",
      "nearest_lon: 254.804\n",
      "nearest lon is bigger\n",
      "nearest lat is smaller\n",
      "crop_lon_idx_min: 0\n",
      "crop_lon_idx_max: 7\n",
      "crop_lat_idx_min: 0\n",
      "crop_lat_idx_max: 7\n",
      "Lon values after cropping: [253.804 254.054 254.304 254.554 254.804 255.054 255.304 255.554]\n",
      "Lat values after cropping: [40.95     40.699875 40.44975  40.199625 39.9495   39.699375 39.44925\n",
      " 39.199125]\n",
      "train args: --data-root-dir /var/folders/yj/k7pg73d56rl366r8bvlbncgm0000gn/T/tmpxrz6o9jp\n",
      "            --data-names era5_merged.nc,cleaned.nc\n",
      "            --data-types tas,tas\n",
      "            --n-target-data 1\n",
      "            --encoding-layers 3\n",
      "            --pooling-layers 0\n",
      "            --device cpu\n",
      "            --n-filters 18\n",
      "            --out-channels 1\n",
      "            --snapshot-dir /var/folders/yj/k7pg73d56rl366r8bvlbncgm0000gn/T/tmp9gm7spn1\n",
      "            --n-threads 0\n",
      "            --max-iter 1000\n",
      "            --log-interval 5000\n",
      "            --loss-criterion 3\n",
      "            --log-dir /var/folders/yj/k7pg73d56rl366r8bvlbncgm0000gn/T/tmp7hc9r4zi\n",
      "            --normalize-data\n",
      "Active conda environment: crai\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--data-root-dir DATA_ROOT_DIR]\n",
      "                             [--mask-dir MASK_DIR] [--log-dir LOG_DIR]\n",
      "                             [--data-names DATA_NAMES]\n",
      "                             [--mask-names MASK_NAMES]\n",
      "                             [--data-types DATA_TYPES]\n",
      "                             [--n-target-data N_TARGET_DATA] [--device DEVICE]\n",
      "                             [--shuffle-masks] [--channel-steps CHANNEL_STEPS]\n",
      "                             [--lstm-steps LSTM_STEPS] [--gru-steps GRU_STEPS]\n",
      "                             [--encoding-layers ENCODING_LAYERS]\n",
      "                             [--pooling-layers POOLING_LAYERS]\n",
      "                             [--conv-factor CONV_FACTOR] [--weights WEIGHTS]\n",
      "                             [--steady-masks STEADY_MASKS]\n",
      "                             [--loop-random-seed LOOP_RANDOM_SEED]\n",
      "                             [--cuda-random-seed CUDA_RANDOM_SEED]\n",
      "                             [--deterministic] [--attention]\n",
      "                             [--channel-reduction-rate CHANNEL_REDUCTION_RATE]\n",
      "                             [--disable-skip-layers] [--disable-first-bn]\n",
      "                             [--masked-bn] [--lazy-load] [--global-padding]\n",
      "                             [--normalize-data] [--n-filters N_FILTERS]\n",
      "                             [--out-channels OUT_CHANNELS]\n",
      "                             [--dataset-name DATASET_NAME]\n",
      "                             [--min-bounds MIN_BOUNDS]\n",
      "                             [--max-bounds MAX_BOUNDS] [--profile]\n",
      "                             [--val-names VAL_NAMES]\n",
      "                             [--snapshot-dir SNAPSHOT_DIR]\n",
      "                             [--resume-iter RESUME_ITER]\n",
      "                             [--batch-size BATCH_SIZE] [--n-threads N_THREADS]\n",
      "                             [--multi-gpus] [--finetune] [--lr LR]\n",
      "                             [--lr-finetune LR_FINETUNE] [--max-iter MAX_ITER]\n",
      "                             [--log-interval LOG_INTERVAL]\n",
      "                             [--lr-scheduler-patience LR_SCHEDULER_PATIENCE]\n",
      "                             [--save-model-interval SAVE_MODEL_INTERVAL]\n",
      "                             [--n-final-models N_FINAL_MODELS]\n",
      "                             [--final-models-interval FINAL_MODELS_INTERVAL]\n",
      "                             [--loss-criterion LOSS_CRITERION]\n",
      "                             [--eval-timesteps EVAL_TIMESTEPS]\n",
      "                             [-f LOAD_FROM_FILE] [--vlim VLIM]\n",
      "                             [--lambda-loss LAMBDA_LOSS]\n",
      "                             [--val-metrics VAL_METRICS]\n",
      "                             [--tensor-plots TENSOR_PLOTS]\n",
      "                             [--early-stopping-delta EARLY_STOPPING_DELTA]\n",
      "                             [--early-stopping-patience EARLY_STOPPING_PATIENCE]\n",
      "                             [--n-iters-val N_ITERS_VAL]\n",
      "ipykernel_launcher.py: error: ambiguous option: --f=/Users/timo.wacke/Library/Jupyter/runtime/kernel-v2-96184adt374QPi8kB.json could match --finetune, --final-models-interval\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timo.wacke/anaconda3/envs/crai/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training = TrainingExecuter(station=marshall_station, ProgressStatus())\n",
    "\n",
    "output_model_path = training.execute()\n",
    "marshall_data.add_model(output_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barbados_station = StationData(\"Barbados\", \"./measurements/Barbados/\")\n",
    "vienna_station = StationData(\"Vienna\", \"./measurements/Vienna/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import pty\n",
    "import os\n",
    "\n",
    "async def run_script():\n",
    "    # Path to your Python script\n",
    "    script_path = \"test.py\"\n",
    "    \n",
    "    # Initialize counter for the number of lines found\n",
    "    line_count = 0\n",
    "    \n",
    "    # Start the subprocess with pty\n",
    "    master, slave = pty.openpty()\n",
    "    process = await asyncio.create_subprocess_exec(\n",
    "        \"python\", script_path,\n",
    "        stdin=slave,\n",
    "        stdout=slave,\n",
    "        stderr=slave\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        # print the length of the output every 5 seconds\n",
    "        while True:\n",
    "            output = os.read(master, 1024).decode()\n",
    "            if not output:\n",
    "                # If there's no more output, break out of the loop\n",
    "                print(\"breaaak\")\n",
    "                break\n",
    "            \n",
    "            line_count += len(output.splitlines())\n",
    "            print(f\"Lines found: {line_count}\")\n",
    "            await asyncio.sleep(5)\n",
    "    except OSError as e:\n",
    "        print(f\"Error reading output: {e}\")\n",
    "    finally:\n",
    "        # Close the file descriptors\n",
    "        os.close(master)\n",
    "        os.close(slave)\n",
    "\n",
    "# Create a task to run the coroutine in the background\n",
    "task = asyncio.create_task(run_script())\n",
    "\n",
    "# Wait for the task to complete\n",
    "await task\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
